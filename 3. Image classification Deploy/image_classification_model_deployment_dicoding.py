# -*- coding: utf-8 -*-
"""Image Classification Model Deployment-Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X0_Q5WvidOfXU8WO28HSHhEaGvDWiNQO

#Profile Submission

> Nama : Hamidan Z Wijasena

> Email : hamidanzaneddinewijasena@gmail.com

#Submission: Image Classification Model Deployment
Requirements 

1. Dataset yang akan dipakai bebas, namun minimal memiliki 1000 buah gambar.
2. Dataset dibagi menjadi 80% train set dan 20% test set.
3. Model harus menggunakan model sequential.
4. Model harus menggunakan Conv2D Maxpooling Layer.
5. Akurasi pada training dan validation set minimal sebesar 80%.
6. Menggunakan Callback.
7. Membuat plot terhadap akurasi dan loss model.
8. Menulis kode untuk menyimpan model ke dalam format TF-Lite.

> Dataset : https://www.kaggle.com/madisona/translated-animals10
"""

#Import dataset dari gdrive

from google.colab import drive
drive.mount('/content/drive/')

# Import Library yang akan digunakan

import os
import shutil
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image

# listing dataset gambar hewan

animals10 = os.path.join('/content/drive/MyDrive/Colab Notebooks/Latihan/Deploy TF-Live/animals10/raw-img/')
print(os.listdir(animals10))

"""# Pre-Processing"""

# Listing dataset gambar

list_animals10 = os.listdir(animals10)
print(list_animals10)

# Print total dataset hewan

total = 0

for x in list_animals10:
  dir = os.path.join(animals10, x)
  y = len(os.listdir(dir))
  print(x + ':', y)
  total = total + y
  
  img_name = os.listdir(dir)
  for z in range(4):
    img_path = os.path.join(dir, img_name[z])
    img = Image.open(img_path)
    print('-',img.size)
  print('---------------')

print('\nTotal :', total)

fig, ax = plt.subplots(2, 2, figsize = (15,15))
fig.suptitle("Randomly displays images.", fontsize = 24)
animals_sorted = sorted(list_animals10)
animals_id = 0
for i in range(2):
  for j in range(2):
    try:
      animals_selected = animals_sorted[animals_id] 
      animals_id += 1
    except:
      break
    if animals_selected == '.TEMP':
        continue
    animals_selected_images = os.listdir(os.path.join(animals10, animals_selected))
    animals_selected_random = np.random.choice(animals_selected_images)
    images = plt.imread(os.path.join(animals10, animals_selected, animals_selected_random))
    ax[i][j].imshow(images)
    ax[i][j].set_title(animals_selected, pad=10, fontsize=22)
    
plt.setp(ax, xticks=[],yticks=[])
plt.show

"""# Model Building"""

train_datagen = ImageDataGenerator(
    rotation_range = 40,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    rescale = 1/255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = 'nearest',
    validation_split = 0.2   
)

batch_size = 256

data_train = train_datagen.flow_from_directory(
    animals10,
    target_size = (150, 150),
    batch_size = batch_size,
    class_mode = 'categorical',
    subset = 'training')

data_val = train_datagen.flow_from_directory(
    animals10, 
    target_size = (150, 150),
    batch_size = batch_size,
    class_mode = 'categorical',
    subset = 'validation')

# Detail Deep Learning Neural Networks Layer 

tf.device('/device:GPU:0')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3 ), activation = 'relu', input_shape = (150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5), 
    tf.keras.layers.Dense(512, activation = 'relu'),
    tf.keras.layers.Dense(4, activation = 'softmax')
])

model.compile(optimizer = 'adam',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

model.summary()

# Callback

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs = {}):
    if(logs.get('accuracy') > 0.93 and logs.get('val_accuracy') > 0.93):
      print("\nAccuracy above 93%, finish training!")
      self.model.stop_training = True

callbacks = myCallback()

# Fitting Model

history = model.fit(data_train, 
                    epochs = 100, 
                    steps_per_epoch = data_train.samples // batch_size,
                    validation_data = data_val, 
                    validation_steps = data_val.samples // batch_size,
                    verbose = 1,
                    callbacks = [callbacks])

"""# Model Evaluation"""

# Plot Hasil Akurasi Training dan Validation

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()

"""# Menulis kode untuk menyimpan model ke dalam format TF-Lite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)